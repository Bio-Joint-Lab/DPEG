## Dual-Protein Embedding-based Graph Model with Dynamic Attention for Activity Prediction

This is the repository for DPEG(originally Lasagna in our previous preprint version).
This repository contains the source code and some datasets used in our paper.

## Abstract

Protein-Protein Interactions (PPIs) are fundamental to biological processes, yet experimental determination of PPIs
remains costly and labor-intensive. While computational methods have emerged as promising alternatives, sequence-based
approaches face critical challenges: (1) effectively capturing long-range dependencies and critical biochemical patterns
in variable-length sequences, and (2) balancing computational efficiency with sensitivity to subtle residue-level
interactions. Here, we present DPEG, a Dual Protein Embedding-based Graph model, which leverages protein language
models (pLMs) to enable robust sequence-driven PPI prediction. Unlike structure-dependent methods, DPEG operates solely
on sequence data, bypassing the need for structural or domain annotations. Specifically, we employ ESM-2 to transform
sequences into residue-level graphs, preserving evolutionary and physicochemical context. To address variable sequence
lengths, we design a module that can represent protein sequences of arbitrary lengths as graph networks at the amino
acid level. Further, a gated attention mechanism is introduced to adaptively refining residue representations,
prioritizing functionally critical motifs. Evaluated on four diverse PPI datasets spanning different species and
interaction types, DPEG achieves state-of-the-art performance and demonstrates strong cross-dataset generalizability.

## Environment

python 3.9
pytorch 2.2.0 (with GPU support)
CuDNN (if not installed, all CuDNNGRU in the source code needs to be
changed to GRU)

[here](https://github.com/Bio-Joint-Lab/DPEG/blob/main/environment/ppi.yaml) is a yml file of the environment.

## folders
- **./data**: Contains the training datasets.
- **./logger**: Stores the training logs.
- **./models**: Saves the trained models after training is completed.
- **./pretrained #**: Holds the pretrained model (`esm2_t30_150M_UR50D`).
- **./process**: Contains contact predictions generated by the pretrained model.
- **./results**: Stores the outcomes of the testing phase.

#note:The ESM-2 model used in this project is `esm2_t30_150M_UR50D`. This model will be automatically downloaded during the
first run of the code. If the download fails, please follow
the [ESM-2 official tutorial](https://github.com/facebookresearch/esm) for manual download.


### Datasets
1. BioGRID multi vaildated physical interaction sets provied in [Hu et al.2021](https://academic.oup.com/bioinformatics/article/38/3/694/6409848) 
2. multiple species dataset# (C. elegans, D. melanogaster and E. coli) provied in [Chen et al.2019](https://doi.org/10.1093/bioinformatics/btz328)
3. virus-human interaction dataset provided in [Hu et al.2021](https://academic.oup.com/bioinformatics/article/38/3/694/6409848)
4. yeast core dataset from DeepFE-PPI provided in [Yao et al. 2019](https://peerj.com/articles/7126)

#note: In all datasets, the suffix `l1500` indicates that the original dataset has been filtered based on protein length. For example:
`CeleganDrosophilaEcoli.actions.filtered.01.l1500.tsv`  
This means that protein sequences with lengths exceeding 1500 have been removed from this dataset, retaining only those sequences with lengths less than or equal to 1500.

## Run DPEG for training

When you want to run DPEG for training, execute `train.py` and pass in two arguments:  
1. **The dataset you intend to use**: The dataset alias and its corresponding path are defined in [here](https://github.com/Bio-Joint-Lab/DPEG/blob/main/data_file_path.json).  
2. **The GPU device you are using**: Specify the GPU index.  

For example:  
```bash  
python train.py 0 0  
```
## Prediction PPI using DPEG
1. **Prepare Datasets:**

    Place your prediction datasets (e.g., AA_database and AA_pair) into ./data/benchmarks/AA (name the folder as needed). Update the paths in ./data_file_path.json as follows:

    - **Database format**: proteinID\tproteinSequence
    - **Pair format:** proteinId1\tproteinId2
    - Update data_file_path.json:
    ```json  
    "your_database_name(AA_or_other)":{ 
     "database": "your_database_dir(AA)/your_database.tsv(AA_database.tsv)", 
     "pair": "your_database_dir(AA)/your_pair.tsv(AA_pair.tsv)"}
    ```
2. **run Prediction Script**
    Execute PPI_prediction.py via command line:
    ```bash  
    python PPI_prediction.py <testDataset> <model_file_name> <cuda_name> 
    ```
    Example:ï¼š
    ```bash  
    python PPI_prediction.py AA /absolute/path/to/your/model cuda:0
    ```
**Notes**
- Ensure the dataset paths in data_file_path.json are absolute paths for cross-platform compatibility.
- The <testDataset> should match the key name defined in data_file_path.json (e.g., AA).
- Replace <model_file_path> with the absolute path to your pre-trained model file.
## Reference
